{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recommender systems** are about recommending something to someone based on data regadring historical activities and/or similarities of other people, their behavior or choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_interests = [\n",
    "    [\"Hadoop\", \"Big Data\", \"HBase\", \"Java\", \"Spark\", \"Storm\", \"Cassandra\"],\n",
    "    [\"NoSQL\", \"MongoDB\", \"Cassandra\", \"HBase\", \"Postgres\"],\n",
    "    [\"Python\", \"scikit-learn\", \"scipy\", \"numpy\", \"statsmodels\", \"pandas\"],\n",
    "    [\"R\", \"Python\", \"statistics\", \"regression\", \"probability\"],\n",
    "    [\"machine learning\", \"regression\", \"decision trees\", \"libsvm\"],\n",
    "    [\"Python\", \"R\", \"Java\", \"C++\", \"Haskell\", \"programming languages\"],\n",
    "    [\"statistics\", \"probability\", \"mathematics\", \"theory\"],\n",
    "    [\"machine learning\", \"scikit-learn\", \"Mahout\", \"neural networks\"],\n",
    "    [\"neural networks\", \"deep learning\", \"Big Data\", \"artificial intelligence\"],\n",
    "    [\"Hadoop\", \"Java\", \"MapReduce\", \"Big Data\"],\n",
    "    [\"statistics\", \"R\", \"statsmodels\"],\n",
    "    [\"C++\", \"deep learning\", \"artificial intelligence\", \"probability\"],\n",
    "    [\"pandas\", \"R\", \"Python\"],\n",
    "    [\"databases\", \"HBase\", \"Postgres\", \"MySQL\", \"MongoDB\"],\n",
    "    [\"libsvm\", \"regression\", \"support vector machines\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommending What's Popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "popular_interests = Counter(interest\n",
    "                            for user_interests in users_interests\n",
    "                            for interest in user_interests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Hadoop': 2,\n",
       "         'Big Data': 3,\n",
       "         'HBase': 3,\n",
       "         'Java': 3,\n",
       "         'Spark': 1,\n",
       "         'Storm': 1,\n",
       "         'Cassandra': 2,\n",
       "         'NoSQL': 1,\n",
       "         'MongoDB': 2,\n",
       "         'Postgres': 2,\n",
       "         'Python': 4,\n",
       "         'scikit-learn': 2,\n",
       "         'scipy': 1,\n",
       "         'numpy': 1,\n",
       "         'statsmodels': 2,\n",
       "         'pandas': 2,\n",
       "         'R': 4,\n",
       "         'statistics': 3,\n",
       "         'regression': 3,\n",
       "         'probability': 3,\n",
       "         'machine learning': 2,\n",
       "         'decision trees': 1,\n",
       "         'libsvm': 2,\n",
       "         'C++': 2,\n",
       "         'Haskell': 1,\n",
       "         'programming languages': 1,\n",
       "         'mathematics': 1,\n",
       "         'theory': 1,\n",
       "         'Mahout': 1,\n",
       "         'neural networks': 2,\n",
       "         'deep learning': 2,\n",
       "         'artificial intelligence': 2,\n",
       "         'MapReduce': 1,\n",
       "         'databases': 1,\n",
       "         'MySQL': 1,\n",
       "         'support vector machines': 1})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suggest to a user the most popular interests that she is not already interested in\n",
    "from typing import List, Tuple\n",
    "\n",
    "def most_popular_new_interests(\n",
    "        user_interests: List[str],\n",
    "        max_results: int = 5) -> List[Tuple[str, int]]:\n",
    "    suggestions = [(interest, frequency)\n",
    "                   for interest, frequency in popular_interests.most_common()\n",
    "                   if interest not in user_interests]\n",
    "    return suggestions[:max_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User interests: ['Hadoop', 'Big Data', 'HBase', 'Java', 'Spark', 'Storm', 'Cassandra']\n",
      "Recommended interests: [('Python', 4), ('R', 4), ('statistics', 3), ('regression', 3), ('probability', 3)]\n"
     ]
    }
   ],
   "source": [
    "user0_interests = users_interests[0]\n",
    "print(f\"User interests: {user0_interests}\")\n",
    "print(f\"Recommended interests: {most_popular_new_interests(user0_interests, 5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, “lots of people are interested in Python, so maybe you should be too” is not the most compelling sales pitch. If someone is brand new to our site and we don’t know anything about them, that’s possibly the best we can do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Based Collaborative Filtering\n",
    "\n",
    "One way of taking a user’s interests into account is to look for users who are somehow `similar` to her, and then suggest the things that those users are interested in. \n",
    "\n",
    "In order to do that, `we’ll need a way to measure how similar two users are`. Here we’ll use `cosine similarity`,  to measure how similar two word vectors were.\n",
    "\n",
    "We’ll apply this to vectors of 0s and 1s, each vector `v `representing one user’s interests. `v[i]` will be 1 if the user specified the ith interest, and 0 otherwise. Accordingly, `“similar users” will mean “users whose interest vectors most nearly point in the same direction.”` Users with identical interests will have similarity 1. Users with no identical interests will have similarity 0. Otherwise, the similarity will fall in between, with numbers closer to 1 indicating “very similar” and numbers closer to 0 indicating “not very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Big Data',\n",
       " 'C++',\n",
       " 'Cassandra',\n",
       " 'HBase',\n",
       " 'Hadoop',\n",
       " 'Haskell',\n",
       " 'Java',\n",
       " 'Mahout',\n",
       " 'MapReduce',\n",
       " 'MongoDB',\n",
       " 'MySQL',\n",
       " 'NoSQL',\n",
       " 'Postgres',\n",
       " 'Python',\n",
       " 'R',\n",
       " 'Spark',\n",
       " 'Storm',\n",
       " 'artificial intelligence',\n",
       " 'databases',\n",
       " 'decision trees',\n",
       " 'deep learning',\n",
       " 'libsvm',\n",
       " 'machine learning',\n",
       " 'mathematics',\n",
       " 'neural networks',\n",
       " 'numpy',\n",
       " 'pandas',\n",
       " 'probability',\n",
       " 'programming languages',\n",
       " 'regression',\n",
       " 'scikit-learn',\n",
       " 'scipy',\n",
       " 'statistics',\n",
       " 'statsmodels',\n",
       " 'support vector machines',\n",
       " 'theory'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use set comprehension to find the unique interests\n",
    "{interest for user_interests in users_interests for interest in user_interests}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_interests = sorted({interest\n",
    "                           for user_interests in users_interests\n",
    "                           for interest in user_interests})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Big Data', 'C++', 'Cassandra', 'HBase', 'Hadoop']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_interests[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce an \"interest\" vector of 0s and 1s for each user\n",
    "def make_user_interest_vector(user_interests: List[str]) -> List[int]:\n",
    "    \"\"\"\n",
    "    Given a list ofinterests, produce a vector whose ith element is 1\n",
    "    if unique_interests[i] is in the list, 0 otherwise\n",
    "    \"\"\"\n",
    "    return [1 if interest in user_interests else 0\n",
    "            for interest in unique_interests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"{make_user_interest_vector(user0_interests)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_interest_vectors = [make_user_interest_vector(user_interests)\n",
    "                         for user_interests in users_interests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2836.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Java 3\n",
      "0 Big Data 3\n",
      "0 Hadoop 2\n",
      "0 HBase 1\n",
      "0 C++ 1\n",
      "0 Spark 1\n",
      "0 Storm 1\n",
      "0 programming languages 1\n",
      "0 MapReduce 1\n",
      "0 Cassandra 1\n",
      "0 deep learning 1\n",
      "1 HBase 2\n",
      "1 neural networks 2\n",
      "1 Postgres 2\n",
      "1 MongoDB 2\n",
      "1 machine learning 2\n",
      "1 Cassandra 1\n",
      "1 numpy 1\n",
      "1 decision trees 1\n",
      "1 deep learning 1\n",
      "1 databases 1\n",
      "1 MySQL 1\n",
      "1 NoSQL 1\n",
      "1 artificial intelligence 1\n",
      "1 scipy 1\n",
      "2 regression 3\n",
      "2 Python 2\n",
      "2 R 2\n",
      "2 libsvm 2\n",
      "2 scikit-learn 2\n",
      "2 mathematics 1\n",
      "2 support vector machines 1\n",
      "2 Haskell 1\n",
      "2 Mahout 1\n",
      "3 statistics 3\n",
      "3 probability 3\n",
      "3 Python 2\n",
      "3 R 2\n",
      "3 pandas 2\n",
      "3 statsmodels 2\n",
      "3 C++ 1\n",
      "3 artificial intelligence 1\n",
      "3 theory 1\n",
      "['Hadoop', 'Big Data', 'HBase', 'Java', 'Spark', 'Storm', 'Cassandra']\n",
      "Big Data and programming languages 7\n",
      "\n",
      "['NoSQL', 'MongoDB', 'Cassandra', 'HBase', 'Postgres']\n",
      "Python and statistics 5\n",
      "\n",
      "['Python', 'scikit-learn', 'scipy', 'numpy', 'statsmodels', 'pandas']\n",
      "Python and statistics 2\n",
      "databases 2\n",
      "machine learning 2\n",
      "\n",
      "['R', 'Python', 'statistics', 'regression', 'probability']\n",
      "machine learning 3\n",
      "databases 2\n",
      "\n",
      "['machine learning', 'regression', 'decision trees', 'libsvm']\n",
      "databases 2\n",
      "Python and statistics 2\n",
      "\n",
      "['Python', 'R', 'Java', 'C++', 'Haskell', 'programming languages']\n",
      "databases 3\n",
      "Big Data and programming languages 3\n",
      "\n",
      "['statistics', 'probability', 'mathematics', 'theory']\n",
      "machine learning 3\n",
      "databases 1\n",
      "\n",
      "['machine learning', 'scikit-learn', 'Mahout', 'neural networks']\n",
      "databases 2\n",
      "Python and statistics 2\n",
      "\n",
      "['neural networks', 'deep learning', 'Big Data', 'artificial intelligence']\n",
      "Python and statistics 3\n",
      "Big Data and programming languages 1\n",
      "\n",
      "['Hadoop', 'Java', 'MapReduce', 'Big Data']\n",
      "Big Data and programming languages 4\n",
      "\n",
      "['statistics', 'R', 'statsmodels']\n",
      "machine learning 3\n",
      "\n",
      "['C++', 'deep learning', 'artificial intelligence', 'probability']\n",
      "machine learning 3\n",
      "Big Data and programming languages 1\n",
      "\n",
      "['pandas', 'R', 'Python']\n",
      "machine learning 3\n",
      "\n",
      "['databases', 'HBase', 'Postgres', 'MySQL', 'MongoDB']\n",
      "Python and statistics 5\n",
      "\n",
      "['libsvm', 'regression', 'support vector machines']\n",
      "databases 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Computer the pairwise similarities using cosine similarity\n",
    "from scratch.nlp import cosine_similarity\n",
    "\n",
    "#for interest_vector_i in user_interest_vectors:\n",
    "    #print(f\"interest_vector_i -> {interest_vector_i}\")\n",
    "\n",
    "user_similarities = [[cosine_similarity(interest_vector_i, interest_vector_j)\n",
    "                      for interest_vector_j in user_interest_vectors]\n",
    "                     for interest_vector_i in user_interest_vectors]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3380617018914066"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarity bewteen users 0 and 1\n",
    "user_similarities[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most similar users\n",
    "def most_similar_users_to(user_id: int) -> List[Tuple[int, float]]:\n",
    "    pairs = [(other_user_id, similarity)                      # Find other\n",
    "             for other_user_id, similarity in                 # users with\n",
    "                enumerate(user_similarities[user_id])         # nonzero\n",
    "             if user_id != other_user_id and similarity > 0]  # similarity.\n",
    "\n",
    "    return sorted(pairs,                                      # Sort them\n",
    "                  key=lambda pair: pair[-1],                  # most similar\n",
    "                  reverse=True)                               # first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9, 0.5669467095138409),\n",
       " (1, 0.3380617018914066),\n",
       " (8, 0.1889822365046136),\n",
       " (13, 0.1690308509457033),\n",
       " (5, 0.1543033499620919)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_users_to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add up similar users' similarities (and exclude your own) to see \n",
    "# in what else a user would be interested in\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def user_based_suggestions(user_id: int,\n",
    "                           include_current_interests: bool = False):\n",
    "    # Sum up the similarities.\n",
    "    suggestions: Dict[str, float] = defaultdict(float)\n",
    "    for other_user_id, similarity in most_similar_users_to(user_id):\n",
    "        print(f\"other_user_id -> {other_user_id}, similarity -> {similarity}\")\n",
    "        for interest in users_interests[other_user_id]:\n",
    "            print(f\"\\tinterest -> {interest}\")\n",
    "            print(f\"\\t\\tbefore: suggestions[{interest}] = {suggestions[interest]}\")\n",
    "            suggestions[interest] += similarity\n",
    "            print(f\"\\t\\tafter: suggestions[{interest}] = {suggestions[interest]}\")\n",
    "\n",
    "    # Convert them to a sorted list.\n",
    "    suggestions = sorted(suggestions.items(),\n",
    "                         key=lambda pair: pair[-1],  # weight\n",
    "                         reverse=True)\n",
    "    \n",
    "    #print(f\"suggestions = {suggestions}\")\n",
    "\n",
    "    # And (maybe) exclude already-interests\n",
    "    if include_current_interests:\n",
    "        return suggestions\n",
    "    else:\n",
    "        return [(suggestion, weight)\n",
    "                for suggestion, weight in suggestions\n",
    "                if suggestion not in users_interests[user_id]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other_user_id -> 9, similarity -> 0.5669467095138409\n",
      "\tinterest -> Hadoop\n",
      "\t\tbefore: suggestions[Hadoop] = 0.0\n",
      "\t\tafter: suggestions[Hadoop] = 0.5669467095138409\n",
      "\tinterest -> Java\n",
      "\t\tbefore: suggestions[Java] = 0.0\n",
      "\t\tafter: suggestions[Java] = 0.5669467095138409\n",
      "\tinterest -> MapReduce\n",
      "\t\tbefore: suggestions[MapReduce] = 0.0\n",
      "\t\tafter: suggestions[MapReduce] = 0.5669467095138409\n",
      "\tinterest -> Big Data\n",
      "\t\tbefore: suggestions[Big Data] = 0.0\n",
      "\t\tafter: suggestions[Big Data] = 0.5669467095138409\n",
      "other_user_id -> 1, similarity -> 0.3380617018914066\n",
      "\tinterest -> NoSQL\n",
      "\t\tbefore: suggestions[NoSQL] = 0.0\n",
      "\t\tafter: suggestions[NoSQL] = 0.3380617018914066\n",
      "\tinterest -> MongoDB\n",
      "\t\tbefore: suggestions[MongoDB] = 0.0\n",
      "\t\tafter: suggestions[MongoDB] = 0.3380617018914066\n",
      "\tinterest -> Cassandra\n",
      "\t\tbefore: suggestions[Cassandra] = 0.0\n",
      "\t\tafter: suggestions[Cassandra] = 0.3380617018914066\n",
      "\tinterest -> HBase\n",
      "\t\tbefore: suggestions[HBase] = 0.0\n",
      "\t\tafter: suggestions[HBase] = 0.3380617018914066\n",
      "\tinterest -> Postgres\n",
      "\t\tbefore: suggestions[Postgres] = 0.0\n",
      "\t\tafter: suggestions[Postgres] = 0.3380617018914066\n",
      "other_user_id -> 8, similarity -> 0.1889822365046136\n",
      "\tinterest -> neural networks\n",
      "\t\tbefore: suggestions[neural networks] = 0.0\n",
      "\t\tafter: suggestions[neural networks] = 0.1889822365046136\n",
      "\tinterest -> deep learning\n",
      "\t\tbefore: suggestions[deep learning] = 0.0\n",
      "\t\tafter: suggestions[deep learning] = 0.1889822365046136\n",
      "\tinterest -> Big Data\n",
      "\t\tbefore: suggestions[Big Data] = 0.5669467095138409\n",
      "\t\tafter: suggestions[Big Data] = 0.7559289460184544\n",
      "\tinterest -> artificial intelligence\n",
      "\t\tbefore: suggestions[artificial intelligence] = 0.0\n",
      "\t\tafter: suggestions[artificial intelligence] = 0.1889822365046136\n",
      "other_user_id -> 13, similarity -> 0.1690308509457033\n",
      "\tinterest -> databases\n",
      "\t\tbefore: suggestions[databases] = 0.0\n",
      "\t\tafter: suggestions[databases] = 0.1690308509457033\n",
      "\tinterest -> HBase\n",
      "\t\tbefore: suggestions[HBase] = 0.3380617018914066\n",
      "\t\tafter: suggestions[HBase] = 0.50709255283711\n",
      "\tinterest -> Postgres\n",
      "\t\tbefore: suggestions[Postgres] = 0.3380617018914066\n",
      "\t\tafter: suggestions[Postgres] = 0.50709255283711\n",
      "\tinterest -> MySQL\n",
      "\t\tbefore: suggestions[MySQL] = 0.0\n",
      "\t\tafter: suggestions[MySQL] = 0.1690308509457033\n",
      "\tinterest -> MongoDB\n",
      "\t\tbefore: suggestions[MongoDB] = 0.3380617018914066\n",
      "\t\tafter: suggestions[MongoDB] = 0.50709255283711\n",
      "other_user_id -> 5, similarity -> 0.1543033499620919\n",
      "\tinterest -> Python\n",
      "\t\tbefore: suggestions[Python] = 0.0\n",
      "\t\tafter: suggestions[Python] = 0.1543033499620919\n",
      "\tinterest -> R\n",
      "\t\tbefore: suggestions[R] = 0.0\n",
      "\t\tafter: suggestions[R] = 0.1543033499620919\n",
      "\tinterest -> Java\n",
      "\t\tbefore: suggestions[Java] = 0.5669467095138409\n",
      "\t\tafter: suggestions[Java] = 0.7212500594759328\n",
      "\tinterest -> C++\n",
      "\t\tbefore: suggestions[C++] = 0.0\n",
      "\t\tafter: suggestions[C++] = 0.1543033499620919\n",
      "\tinterest -> Haskell\n",
      "\t\tbefore: suggestions[Haskell] = 0.0\n",
      "\t\tafter: suggestions[Haskell] = 0.1543033499620919\n",
      "\tinterest -> programming languages\n",
      "\t\tbefore: suggestions[programming languages] = 0.0\n",
      "\t\tafter: suggestions[programming languages] = 0.1543033499620919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('MapReduce', 0.5669467095138409),\n",
       " ('MongoDB', 0.50709255283711),\n",
       " ('Postgres', 0.50709255283711),\n",
       " ('NoSQL', 0.3380617018914066),\n",
       " ('neural networks', 0.1889822365046136),\n",
       " ('deep learning', 0.1889822365046136),\n",
       " ('artificial intelligence', 0.1889822365046136),\n",
       " ('databases', 0.1690308509457033),\n",
       " ('MySQL', 0.1690308509457033),\n",
       " ('Python', 0.1543033499620919),\n",
       " ('R', 0.1543033499620919),\n",
       " ('C++', 0.1543033499620919),\n",
       " ('Haskell', 0.1543033499620919),\n",
       " ('programming languages', 0.1543033499620919)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_based_suggestions(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`This approach doesn’t work as well when the number of items gets very large`. Recall **the curse of dimensionality** - in large-dimensional vector spaces most vectors are very far apart (and also point in very different directions). That is, when there are a large number of interests the “most similar users” to a given user might not be similar at all.\n",
    "\n",
    "Imagine a site like Amazon.com, from which I’ve bought thousands of items over the last couple of decades. You could attempt to identify similar users to me based on buying patterns, but most likely in all the world there’s no one whose purchase history looks even remotely like mine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-Based Collaborative Filtering\n",
    "\n",
    "An alternative approach is to `compute similarities between interests directly`. We can then generate suggestions for each user by aggregating interests that are similar to her current interests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose user-interest matrix so that rows correspond to interests\n",
    "# and columns to users\n",
    "interest_user_matrix = [[user_interest_vector[j]\n",
    "                         for user_interest_vector in user_interest_vectors]\n",
    "                        for j, _ in enumerate(unique_interests)]\n",
    "interest_user_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# users having Big Data interest -> 0, 8, 9\n",
    "interest_user_matrix[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use `cosine similarity` again. If precisely the same users are interested in two topics, their similarity will be 1. If no two users are interested in both topics, their similarity will be 0: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_similarities = [[cosine_similarity(user_vector_i, user_vector_j)\n",
    "                          for user_vector_j in interest_user_matrix]\n",
    "                         for user_vector_i in interest_user_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_interests_to(interest_id: int):\n",
    "    similarities = interest_similarities[interest_id]\n",
    "    pairs = [(unique_interests[other_interest_id], similarity)\n",
    "             for other_interest_id, similarity in enumerate(similarities)\n",
    "             if interest_id != other_interest_id and similarity > 0]\n",
    "    return sorted(pairs,\n",
    "                  key=lambda pair: pair[-1],\n",
    "                  reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hadoop', 0.8164965809277261),\n",
       " ('Java', 0.6666666666666666),\n",
       " ('MapReduce', 0.5773502691896258),\n",
       " ('Spark', 0.5773502691896258),\n",
       " ('Storm', 0.5773502691896258),\n",
       " ('Cassandra', 0.4082482904638631),\n",
       " ('artificial intelligence', 0.4082482904638631),\n",
       " ('deep learning', 0.4082482904638631),\n",
       " ('neural networks', 0.4082482904638631),\n",
       " ('HBase', 0.3333333333333333)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find interests most similar to Big Data\n",
    "most_similar_interests_to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create recommendations for a user by summing up the similarities\n",
    "# of the interests similar to this:\n",
    "\n",
    "def item_based_suggestions(user_id: int,\n",
    "                           include_current_interests: bool = False):\n",
    "    # Add up the similar interests\n",
    "    suggestions = defaultdict(float)\n",
    "    user_interest_vector = user_interest_vectors[user_id]\n",
    "    print(f\"user_interest_vector -> {user_interest_vector}\")\n",
    "    for interest_id, is_interested in enumerate(user_interest_vector):\n",
    "        print(f\"\\tinterest_id -> {interest_id}, is_interested -> {is_interested}\")\n",
    "        if is_interested == 1:\n",
    "            similar_interests = most_similar_interests_to(interest_id)\n",
    "            print(f\"\\t\\tsimilar_interests -> {similar_interests}\")\n",
    "            for interest, similarity in similar_interests:\n",
    "                suggestions[interest] += similarity\n",
    "                print(f\"\\t\\t\\tinterest -> {interest}, similarity -> {similarity}\")\n",
    "                print(f\"\\t\\t\\tsuggestions[{interest}] = {suggestions[interest]}\")\n",
    "\n",
    "    # Sort them by weight\n",
    "    suggestions = sorted(suggestions.items(),\n",
    "                         key=lambda pair: pair[-1],\n",
    "                         reverse=True)\n",
    "\n",
    "    if include_current_interests:\n",
    "        return suggestions\n",
    "    else:\n",
    "        return [(suggestion, weight)\n",
    "                for suggestion, weight in suggestions\n",
    "                if suggestion not in users_interests[user_id]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_interest_vector -> [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\tinterest_id -> 0, is_interested -> 1\n",
      "\t\tsimilar_interests -> [('Hadoop', 0.8164965809277261), ('Java', 0.6666666666666666), ('MapReduce', 0.5773502691896258), ('Spark', 0.5773502691896258), ('Storm', 0.5773502691896258), ('Cassandra', 0.4082482904638631), ('artificial intelligence', 0.4082482904638631), ('deep learning', 0.4082482904638631), ('neural networks', 0.4082482904638631), ('HBase', 0.3333333333333333)]\n",
      "\t\t\tinterest -> Hadoop, similarity -> 0.8164965809277261\n",
      "\t\t\tsuggestions[Hadoop] = 0.8164965809277261\n",
      "\t\t\tinterest -> Java, similarity -> 0.6666666666666666\n",
      "\t\t\tsuggestions[Java] = 0.6666666666666666\n",
      "\t\t\tinterest -> MapReduce, similarity -> 0.5773502691896258\n",
      "\t\t\tsuggestions[MapReduce] = 0.5773502691896258\n",
      "\t\t\tinterest -> Spark, similarity -> 0.5773502691896258\n",
      "\t\t\tsuggestions[Spark] = 0.5773502691896258\n",
      "\t\t\tinterest -> Storm, similarity -> 0.5773502691896258\n",
      "\t\t\tsuggestions[Storm] = 0.5773502691896258\n",
      "\t\t\tinterest -> Cassandra, similarity -> 0.4082482904638631\n",
      "\t\t\tsuggestions[Cassandra] = 0.4082482904638631\n",
      "\t\t\tinterest -> artificial intelligence, similarity -> 0.4082482904638631\n",
      "\t\t\tsuggestions[artificial intelligence] = 0.4082482904638631\n",
      "\t\t\tinterest -> deep learning, similarity -> 0.4082482904638631\n",
      "\t\t\tsuggestions[deep learning] = 0.4082482904638631\n",
      "\t\t\tinterest -> neural networks, similarity -> 0.4082482904638631\n",
      "\t\t\tsuggestions[neural networks] = 0.4082482904638631\n",
      "\t\t\tinterest -> HBase, similarity -> 0.3333333333333333\n",
      "\t\t\tsuggestions[HBase] = 0.3333333333333333\n",
      "\tinterest_id -> 1, is_interested -> 0\n",
      "\tinterest_id -> 2, is_interested -> 1\n",
      "\t\tsimilar_interests -> [('HBase', 0.8164965809277261), ('NoSQL', 0.7071067811865475), ('Spark', 0.7071067811865475), ('Storm', 0.7071067811865475), ('Hadoop', 0.5), ('MongoDB', 0.5), ('Postgres', 0.5), ('Big Data', 0.4082482904638631), ('Java', 0.4082482904638631)]\n",
      "\t\t\tinterest -> HBase, similarity -> 0.8164965809277261\n",
      "\t\t\tsuggestions[HBase] = 1.1498299142610595\n",
      "\t\t\tinterest -> NoSQL, similarity -> 0.7071067811865475\n",
      "\t\t\tsuggestions[NoSQL] = 0.7071067811865475\n",
      "\t\t\tinterest -> Spark, similarity -> 0.7071067811865475\n",
      "\t\t\tsuggestions[Spark] = 1.2844570503761732\n",
      "\t\t\tinterest -> Storm, similarity -> 0.7071067811865475\n",
      "\t\t\tsuggestions[Storm] = 1.2844570503761732\n",
      "\t\t\tinterest -> Hadoop, similarity -> 0.5\n",
      "\t\t\tsuggestions[Hadoop] = 1.3164965809277263\n",
      "\t\t\tinterest -> MongoDB, similarity -> 0.5\n",
      "\t\t\tsuggestions[MongoDB] = 0.5\n",
      "\t\t\tinterest -> Postgres, similarity -> 0.5\n",
      "\t\t\tsuggestions[Postgres] = 0.5\n",
      "\t\t\tinterest -> Big Data, similarity -> 0.4082482904638631\n",
      "\t\t\tsuggestions[Big Data] = 0.4082482904638631\n",
      "\t\t\tinterest -> Java, similarity -> 0.4082482904638631\n",
      "\t\t\tsuggestions[Java] = 1.0749149571305296\n",
      "\tinterest_id -> 3, is_interested -> 1\n",
      "\t\tsimilar_interests -> [('Cassandra', 0.8164965809277261), ('MongoDB', 0.8164965809277261), ('Postgres', 0.8164965809277261), ('MySQL', 0.5773502691896258), ('NoSQL', 0.5773502691896258), ('Spark', 0.5773502691896258), ('Storm', 0.5773502691896258), ('databases', 0.5773502691896258), ('Hadoop', 0.4082482904638631), ('Big Data', 0.3333333333333333), ('Java', 0.3333333333333333)]\n",
      "\t\t\tinterest -> Cassandra, similarity -> 0.8164965809277261\n",
      "\t\t\tsuggestions[Cassandra] = 1.2247448713915892\n",
      "\t\t\tinterest -> MongoDB, similarity -> 0.8164965809277261\n",
      "\t\t\tsuggestions[MongoDB] = 1.3164965809277263\n",
      "\t\t\tinterest -> Postgres, similarity -> 0.8164965809277261\n",
      "\t\t\tsuggestions[Postgres] = 1.3164965809277263\n",
      "\t\t\tinterest -> MySQL, similarity -> 0.5773502691896258\n",
      "\t\t\tsuggestions[MySQL] = 0.5773502691896258\n",
      "\t\t\tinterest -> NoSQL, similarity -> 0.5773502691896258\n",
      "\t\t\tsuggestions[NoSQL] = 1.2844570503761732\n",
      "\t\t\tinterest -> Spark, similarity -> 0.5773502691896258\n",
      "\t\t\tsuggestions[Spark] = 1.861807319565799\n",
      "\t\t\tinterest -> Storm, similarity -> 0.5773502691896258\n",
      "\t\t\tsuggestions[Storm] = 1.861807319565799\n",
      "\t\t\tinterest -> databases, similarity -> 0.5773502691896258\n",
      "\t\t\tsuggestions[databases] = 0.5773502691896258\n",
      "\t\t\tinterest -> Hadoop, similarity -> 0.4082482904638631\n",
      "\t\t\tsuggestions[Hadoop] = 1.7247448713915894\n",
      "\t\t\tinterest -> Big Data, similarity -> 0.3333333333333333\n",
      "\t\t\tsuggestions[Big Data] = 0.7415816237971964\n",
      "\t\t\tinterest -> Java, similarity -> 0.3333333333333333\n",
      "\t\t\tsuggestions[Java] = 1.408248290463863\n",
      "\tinterest_id -> 4, is_interested -> 1\n",
      "\t\tsimilar_interests -> [('Big Data', 0.8164965809277261), ('Java', 0.8164965809277261), ('MapReduce', 0.7071067811865475), ('Spark', 0.7071067811865475), ('Storm', 0.7071067811865475), ('Cassandra', 0.5), ('HBase', 0.4082482904638631)]\n",
      "\t\t\tinterest -> Big Data, similarity -> 0.8164965809277261\n",
      "\t\t\tsuggestions[Big Data] = 1.5580782047249224\n",
      "\t\t\tinterest -> Java, similarity -> 0.8164965809277261\n",
      "\t\t\tsuggestions[Java] = 2.224744871391589\n",
      "\t\t\tinterest -> MapReduce, similarity -> 0.7071067811865475\n",
      "\t\t\tsuggestions[MapReduce] = 1.2844570503761732\n",
      "\t\t\tinterest -> Spark, similarity -> 0.7071067811865475\n",
      "\t\t\tsuggestions[Spark] = 2.5689141007523464\n",
      "\t\t\tinterest -> Storm, similarity -> 0.7071067811865475\n",
      "\t\t\tsuggestions[Storm] = 2.5689141007523464\n",
      "\t\t\tinterest -> Cassandra, similarity -> 0.5\n",
      "\t\t\tsuggestions[Cassandra] = 1.7247448713915892\n",
      "\t\t\tinterest -> HBase, similarity -> 0.4082482904638631\n",
      "\t\t\tsuggestions[HBase] = 1.5580782047249226\n",
      "\tinterest_id -> 5, is_interested -> 0\n",
      "\tinterest_id -> 6, is_interested -> 1\n",
      "\t\tsimilar_interests -> [('Hadoop', 0.8164965809277261), ('Big Data', 0.6666666666666666), ('Haskell', 0.5773502691896258), ('MapReduce', 0.5773502691896258), ('Spark', 0.5773502691896258), ('Storm', 0.5773502691896258), ('programming languages', 0.5773502691896258), ('C++', 0.4082482904638631), ('Cassandra', 0.4082482904638631), ('HBase', 0.3333333333333333), ('Python', 0.2886751345948129), ('R', 0.2886751345948129)]\n",
      "\t\t\tinterest -> Hadoop, similarity -> 0.8164965809277261\n",
      "\t\t\tsuggestions[Hadoop] = 2.5412414523193156\n",
      "\t\t\tinterest -> Big Data, similarity -> 0.6666666666666666\n",
      "\t\t\tsuggestions[Big Data] = 2.224744871391589\n",
      "\t\t\tinterest -> Haskell, similarity -> 0.5773502691896258\n",
      "\t\t\tsuggestions[Haskell] = 0.5773502691896258\n",
      "\t\t\tinterest -> MapReduce, similarity -> 0.5773502691896258\n",
      "\t\t\tsuggestions[MapReduce] = 1.861807319565799\n",
      "\t\t\tinterest -> Spark, similarity -> 0.5773502691896258\n",
      "\t\t\tsuggestions[Spark] = 3.146264369941972\n",
      "\t\t\tinterest -> Storm, similarity -> 0.5773502691896258\n",
      "\t\t\tsuggestions[Storm] = 3.146264369941972\n",
      "\t\t\tinterest -> programming languages, similarity -> 0.5773502691896258\n",
      "\t\t\tsuggestions[programming languages] = 0.5773502691896258\n",
      "\t\t\tinterest -> C++, similarity -> 0.4082482904638631\n",
      "\t\t\tsuggestions[C++] = 0.4082482904638631\n",
      "\t\t\tinterest -> Cassandra, similarity -> 0.4082482904638631\n",
      "\t\t\tsuggestions[Cassandra] = 2.132993161855452\n",
      "\t\t\tinterest -> HBase, similarity -> 0.3333333333333333\n",
      "\t\t\tsuggestions[HBase] = 1.891411538058256\n",
      "\t\t\tinterest -> Python, similarity -> 0.2886751345948129\n",
      "\t\t\tsuggestions[Python] = 0.2886751345948129\n",
      "\t\t\tinterest -> R, similarity -> 0.2886751345948129\n",
      "\t\t\tsuggestions[R] = 0.2886751345948129\n",
      "\tinterest_id -> 7, is_interested -> 0\n",
      "\tinterest_id -> 8, is_interested -> 0\n",
      "\tinterest_id -> 9, is_interested -> 0\n",
      "\tinterest_id -> 10, is_interested -> 0\n",
      "\tinterest_id -> 11, is_interested -> 0\n",
      "\tinterest_id -> 12, is_interested -> 0\n",
      "\tinterest_id -> 13, is_interested -> 0\n",
      "\tinterest_id -> 14, is_interested -> 0\n",
      "\tinterest_id -> 15, is_interested -> 1\n",
      "\t\tsimilar_interests -> [('Storm', 1.0), ('Cassandra', 0.7071067811865475), ('Hadoop', 0.7071067811865475), ('Big Data', 0.5773502691896258), ('HBase', 0.5773502691896258), ('Java', 0.5773502691896258)]\n",
      "\t\t\tinterest -> Storm, similarity -> 1.0\n",
      "\t\t\tsuggestions[Storm] = 4.146264369941973\n",
      "\t\t\tinterest -> Cassandra, similarity -> 0.7071067811865475\n",
      "\t\t\tsuggestions[Cassandra] = 2.8400999430419995\n",
      "\t\t\tinterest -> Hadoop, similarity -> 0.7071067811865475\n",
      "\t\t\tsuggestions[Hadoop] = 3.248348233505863\n",
      "\t\t\tinterest -> Big Data, similarity -> 0.5773502691896258\n",
      "\t\t\tsuggestions[Big Data] = 2.8020951405812147\n",
      "\t\t\tinterest -> HBase, similarity -> 0.5773502691896258\n",
      "\t\t\tsuggestions[HBase] = 2.4687618072478816\n",
      "\t\t\tinterest -> Java, similarity -> 0.5773502691896258\n",
      "\t\t\tsuggestions[Java] = 2.8020951405812147\n",
      "\tinterest_id -> 16, is_interested -> 1\n",
      "\t\tsimilar_interests -> [('Spark', 1.0), ('Cassandra', 0.7071067811865475), ('Hadoop', 0.7071067811865475), ('Big Data', 0.5773502691896258), ('HBase', 0.5773502691896258), ('Java', 0.5773502691896258)]\n",
      "\t\t\tinterest -> Spark, similarity -> 1.0\n",
      "\t\t\tsuggestions[Spark] = 4.146264369941973\n",
      "\t\t\tinterest -> Cassandra, similarity -> 0.7071067811865475\n",
      "\t\t\tsuggestions[Cassandra] = 3.547206724228547\n",
      "\t\t\tinterest -> Hadoop, similarity -> 0.7071067811865475\n",
      "\t\t\tsuggestions[Hadoop] = 3.9554550146924106\n",
      "\t\t\tinterest -> Big Data, similarity -> 0.5773502691896258\n",
      "\t\t\tsuggestions[Big Data] = 3.3794454097708404\n",
      "\t\t\tinterest -> HBase, similarity -> 0.5773502691896258\n",
      "\t\t\tsuggestions[HBase] = 3.0461120764375074\n",
      "\t\t\tinterest -> Java, similarity -> 0.5773502691896258\n",
      "\t\t\tsuggestions[Java] = 3.3794454097708404\n",
      "\tinterest_id -> 17, is_interested -> 0\n",
      "\tinterest_id -> 18, is_interested -> 0\n",
      "\tinterest_id -> 19, is_interested -> 0\n",
      "\tinterest_id -> 20, is_interested -> 0\n",
      "\tinterest_id -> 21, is_interested -> 0\n",
      "\tinterest_id -> 22, is_interested -> 0\n",
      "\tinterest_id -> 23, is_interested -> 0\n",
      "\tinterest_id -> 24, is_interested -> 0\n",
      "\tinterest_id -> 25, is_interested -> 0\n",
      "\tinterest_id -> 26, is_interested -> 0\n",
      "\tinterest_id -> 27, is_interested -> 0\n",
      "\tinterest_id -> 28, is_interested -> 0\n",
      "\tinterest_id -> 29, is_interested -> 0\n",
      "\tinterest_id -> 30, is_interested -> 0\n",
      "\tinterest_id -> 31, is_interested -> 0\n",
      "\tinterest_id -> 32, is_interested -> 0\n",
      "\tinterest_id -> 33, is_interested -> 0\n",
      "\tinterest_id -> 34, is_interested -> 0\n",
      "\tinterest_id -> 35, is_interested -> 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('MapReduce', 1.861807319565799),\n",
       " ('MongoDB', 1.3164965809277263),\n",
       " ('Postgres', 1.3164965809277263),\n",
       " ('NoSQL', 1.2844570503761732),\n",
       " ('MySQL', 0.5773502691896258),\n",
       " ('databases', 0.5773502691896258),\n",
       " ('Haskell', 0.5773502691896258),\n",
       " ('programming languages', 0.5773502691896258),\n",
       " ('artificial intelligence', 0.4082482904638631),\n",
       " ('deep learning', 0.4082482904638631),\n",
       " ('neural networks', 0.4082482904638631),\n",
       " ('C++', 0.4082482904638631),\n",
       " ('Python', 0.2886751345948129),\n",
       " ('R', 0.2886751345948129)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_based_suggestions(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization\n",
    "\n",
    "In this section we’ll assume we have such ratings data and try to `learn a model that can predict the rating for a given user and item`.\n",
    "\n",
    "One way of approaching the problem is to assume that every user has some `latent “type,”` which can be represented as a vector of numbers, and that each item similarly has some latent “type.”\n",
    "\n",
    "If the user types are represented as a `[num_users, dim]` matrix, and the transpose of the item types is represented as a `[dim, num_items]` matrix, their product is a `[num_users, num_items]` matrix. Accordingly, one way of building such a model is by **“factoring” the preferences matrix** into the product of a user matrix and an item matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset from: https://grouplens.org/datasets/movielens/ml-100k.zip\n",
    "MOVIES = \"data/ml-100k/u.item\"   # pipe-delimited: movie_id|title|...\n",
    "RATINGS = \"data/ml-100k/u.data\"  # tab-delimited: user_id, movie_id, rating, timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "    \n",
    "class Rating(NamedTuple):\n",
    "    user_id: str\n",
    "    movie_id: str\n",
    "    rating: float\n",
    "\n",
    "import csv\n",
    "# We specify this encoding to avoid a UnicodeDecodeError.\n",
    "# see: https://stackoverflow.com/a/53136168/1076346\n",
    "with open(MOVIES, encoding=\"iso-8859-1\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"|\")\n",
    "    movies = {movie_id: title for movie_id, title, *_ in reader}\n",
    "\n",
    "# Create a list of [Rating]\n",
    "with open(RATINGS, encoding=\"iso-8859-1\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    ratings = [Rating(user_id, movie_id, float(rating))\n",
    "               for user_id, movie_id, rating, _ in reader]\n",
    "\n",
    "# 1682 movies rated by 943 users\n",
    "assert len(movies) == 1682\n",
    "assert len(list({rating.user_id for rating in ratings})) == 943"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.36 Star Wars (1977)\n",
      "4.20 Empire Strikes Back, The (1980)\n",
      "4.01 Return of the Jedi (1983)\n"
     ]
    }
   ],
   "source": [
    "# Exemplary EDA for an average ratings for Star Wars movies\n",
    "import re\n",
    "    \n",
    "# Data structure for accumulating ratings by movie_id\n",
    "star_wars_ratings = {movie_id: []\n",
    "                     for movie_id, title in movies.items()\n",
    "                     if re.search(\"Star Wars|Empire Strikes|Jedi\", title)}\n",
    "\n",
    "# Iterate over ratings, accumulating the Star Wars ones\n",
    "for rating in ratings:\n",
    "    if rating.movie_id in star_wars_ratings:\n",
    "        star_wars_ratings[rating.movie_id].append(rating.rating)\n",
    "\n",
    "# Compute the average rating for each movie\n",
    "avg_ratings = [(sum(title_ratings) / len(title_ratings), movie_id)\n",
    "               for movie_id, title_ratings in star_wars_ratings.items()]\n",
    "\n",
    "# And then print them in order\n",
    "for avg_rating, movie_id in sorted(avg_ratings, reverse=True):\n",
    "    print(f\"{avg_rating:.2f} {movies[movie_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model to predict these ratings\n",
    "\n",
    "# Train, Validation, Test split\n",
    "import random\n",
    "random.seed(0)\n",
    "random.shuffle(ratings)\n",
    "\n",
    "split1 = int(len(ratings) * 0.7)\n",
    "split2 = int(len(ratings) * 0.85)\n",
    "\n",
    "train = ratings[:split1]              # 70% of the data\n",
    "validation = ratings[split1:split2]   # 15% of the data\n",
    "test = ratings[split2:]               # 15% of the data\n",
    "\n",
    "# Simple baseline model to make sure ours does better than that\n",
    "avg_rating = sum(rating.rating for rating in train) / len(train)\n",
    "baseline_error = sum((rating.rating - avg_rating) ** 2\n",
    "                     for rating in test) / len(test)\n",
    "\n",
    "# This is what we hope to do better than\n",
    "assert 1.26 < baseline_error < 1.27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given our embeddings, the predicted ratings are given by the matrix product of the user embeddings and the movie embeddings. For a given user and movie, that value is just the `dot product` of the corresponding embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding vectors for matrix factorization model\n",
    "    \n",
    "from scratch.deep_learning import random_tensor\n",
    "\n",
    "EMBEDDING_DIM = 2\n",
    "\n",
    "# Find unique ids\n",
    "user_ids = {rating.user_id for rating in ratings}\n",
    "movie_ids = {rating.movie_id for rating in ratings}\n",
    "\n",
    "# Then create a random vector per id\n",
    "user_vectors = {user_id: random_tensor(EMBEDDING_DIM)\n",
    "                for user_id in user_ids}\n",
    "movie_vectors = {movie_id: random_tensor(EMBEDDING_DIM)\n",
    "                 for movie_id in movie_ids}\n",
    "\n",
    "\n",
    "# Training loop for matrix factorization model\n",
    "\n",
    "from typing import List\n",
    "import tqdm\n",
    "from scratch.linear_algebra import dot\n",
    "\n",
    "def loop(dataset: List[Rating],\n",
    "         learning_rate: float = None) -> None:\n",
    "    with tqdm.tqdm(dataset) as t:\n",
    "        loss = 0.0\n",
    "        for i, rating in enumerate(t):\n",
    "            movie_vector = movie_vectors[rating.movie_id]\n",
    "            user_vector = user_vectors[rating.user_id]\n",
    "            predicted = dot(user_vector, movie_vector)\n",
    "            error = predicted - rating.rating\n",
    "            loss += error ** 2\n",
    "\n",
    "            if learning_rate is not None:\n",
    "                #     predicted = m_0 * u_0 + ... + m_k * u_k\n",
    "                # So each u_j enters output with coefficent m_j\n",
    "                # and each m_j enters output with coefficient u_j\n",
    "                user_gradient = [error * m_j for m_j in movie_vector]\n",
    "                movie_gradient = [error * u_j for u_j in user_vector]\n",
    "\n",
    "                # Take gradient steps\n",
    "                for j in range(EMBEDDING_DIM):\n",
    "                    user_vector[j] -= learning_rate * user_gradient[j]\n",
    "                    movie_vector[j] -= learning_rate * movie_gradient[j]\n",
    "\n",
    "            t.set_description(f\"avg loss: {loss / (i + 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 13.994627461331447:   0%|          | 95/70000 [00:00<01:13, 945.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.045000000000000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 15.206879750340253:   4%|▍         | 2893/70000 [00:02<01:01, 1095.68it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "avg loss: 14.88271656157683:  10%|▉         | 6743/70000 [00:06<00:53, 1181.82it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "avg loss: 14.558705811053699:  15%|█▌        | 10810/70000 [00:09<01:01, 965.58it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "avg loss: 13.854534094870566:  23%|██▎       | 16273/70000 [00:14<00:48, 1104.11it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "avg loss: 12.706228426909071:  29%|██▉       | 20492/70000 [00:19<00:48, 1015.86it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "avg loss: 11.56522945014613:  35%|███▍      | 24267/70000 [00:22<00:45, 1013.78it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "avg loss: 10.481219281912546:  40%|████      | 28237/70000 [00:26<00:41, 995.67it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "avg loss: 9.589966026868487:  46%|████▌     | 31942/70000 [00:29<00:36, 1038.89it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "avg loss: 8.645405734677404:  52%|█████▏    | 36745/70000 [00:34<00:38, 855.43it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "avg loss: 1.114797509808072:  80%|████████  | 56055/70000 [00:53<00:12, 1124.58it/s] "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "learning_rate = 0.05\n",
    "for epoch in range(2): # originally 20\n",
    "    learning_rate *= 0.9\n",
    "    print(epoch, learning_rate)\n",
    "    loop(train, learning_rate=learning_rate)\n",
    "    loop(validation)\n",
    "loop(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the learned vectors\n",
    "from scratch.working_with_data import pca, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_vectors = [vector for vector in movie_vectors.values()]\n",
    "components = pca(original_vectors, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform our vectors to represent the PCA and join in the movie IDs and average ratings\n",
    "ratings_by_movie = defaultdict(list)\n",
    "for rating in ratings:\n",
    "    ratings_by_movie[rating.movie_id].append(rating.rating)\n",
    "\n",
    "vectors = [\n",
    "    (movie_id,\n",
    "     sum(ratings_by_movie[movie_id]) / len(ratings_by_movie[movie_id]),\n",
    "     movies[movie_id],\n",
    "     vector)\n",
    "    for movie_id, vector in zip(movie_vectors.keys(),\n",
    "                                transform(original_vectors, components))\n",
    "]\n",
    "\n",
    "# Print top 25 and bottom 25 by first principal component\n",
    "print(sorted(vectors, key=lambda v: v[-1][0])[:25])\n",
    "print(sorted(vectors, key=lambda v: v[-1][0])[-25:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [Surprise](http://surpriselib.com/) - Surprise is a Python scikit building and analyzing recommender systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
