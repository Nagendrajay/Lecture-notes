{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Analysis\n",
    "\n",
    "Many interesting data problems can be fruitfully thought of in terms of **networks**, consisting of `nodes` of some type and the `edges` that join them.\n",
    "\n",
    "For instance, your Facebook friends form the `nodes` of a network whose `edges` are friendship relations. A less obvious example is the World Wide Web itself, with each web page a `node` and each hyperlink from one page to another an `edge`. The nodes can be `undirected` (connecting two nodes both ways) or `directed` (connecting two nodes one way only)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "1. **degree centrality** - most connected nodes.\n",
    "2. **betweenness centrality** - identifies nodel which frequently are on the shortest paths between pairs of other nodel. In particular, the betweenness centrality of node i is computed by adding up, for every other pair of nodes j and k, the proportion of shortest paths between node j and node k that pass through i.\n",
    "3. **closesess centrality** - XXXXXXXXXXXXXXX\n",
    "4. **eigenvector centrality** - nodes with high eigenvector centrality should be those who have a lot of connections, and connections to other nodes whis themselves have high centrality.\n",
    "5. **number of endorsements** - or any other user-based activities.\n",
    "6. **PageRank**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [\n",
    "        { \"id\": 0, \"name\": \"Hero\" },\n",
    "        { \"id\": 1, \"name\": \"Dunn\" },\n",
    "        { \"id\": 2, \"name\": \"Sue\" },\n",
    "        { \"id\": 3, \"name\": \"Chi\" },\n",
    "        { \"id\": 4, \"name\": \"Thor\" },\n",
    "        { \"id\": 5, \"name\": \"Clive\" },\n",
    "        { \"id\": 6, \"name\": \"Hicks\" },\n",
    "        { \"id\": 7, \"name\": \"Devin\" },\n",
    "        { \"id\": 8, \"name\": \"Kate\" },\n",
    "        { \"id\": 9, \"name\": \"Klein\" }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "friendship_pairs = [(0, 1), (0, 2), (1, 2), (1, 3), (2, 3), (3, 4),\n",
    "                   (4, 5), (5, 6), (5, 7), (6, 8), (7, 8), (8, 9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the tuple (0, 1) indicates that the data scientist with id 0 (Hero) and the data scientist with id 1 (Dunn) are friends.\n",
    "\n",
    "<img src=\"images/fig01-01.png\" alt=\"Analytics, Data Science, Machine Learning\" style=\"width: 800px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Degree centrality - Finding Key Connectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find friends\n",
    "def find_friends(node_id, friendship_pairs):\n",
    "    '''\n",
    "    Returns friends of a specific person using friendship_pairs.\n",
    "    \n",
    "    Args:\n",
    "        node_id (int): The id of a node.\n",
    "        friendship_map (list): a list of (X, Y) tuples, where X and Y are nodes id.\n",
    "\n",
    "    Returns:\n",
    "        friends (list): a list of friends id.\n",
    "    '''\n",
    "    friends = []\n",
    "    for friendship in friendship_pairs:\n",
    "        if friendship[0] == node_id:\n",
    "            friends.append(friendship[1])\n",
    "        if friendship[1] == node_id:\n",
    "            friends.append(friendship[0])\n",
    "    return friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 3]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_friends(1, friendship_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [], 1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: []}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the dict with an empty list for each user id:\n",
    "friendships = {user[\"id\"]: [] for user in users}\n",
    "friendships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And loop over the friendship pairs to populate it:\n",
    "for i, j in friendship_pairs:\n",
    "    friendships[i].append(j)  # Add j as a friend of user i\n",
    "    friendships[j].append(i)  # Add i as a friend of user j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [1, 2],\n",
       " 1: [0, 2, 3],\n",
       " 2: [0, 1, 3],\n",
       " 3: [1, 2, 4],\n",
       " 4: [3, 5],\n",
       " 5: [4, 6, 7],\n",
       " 6: [5, 8],\n",
       " 7: [5, 8],\n",
       " 8: [6, 7, 9],\n",
       " 9: [8]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friendships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the average number of connections?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_friends(user, friendships):\n",
    "    '''\n",
    "    Returns a number friends of a specific user and friendships.\n",
    "    \n",
    "    Args:\n",
    "        user (list): a list of dics { \"id\": 0, \"name\": \"Hero\" }\n",
    "        friendships (dict): a list of dics {0: [1, 2]}\n",
    "\n",
    "    Returns:\n",
    "        friends_count (int): number of friends of a specified user.\n",
    "    '''\n",
    "    user_id = user[\"id\"]\n",
    "    #print(user_id)\n",
    "    friend_ids = friendships[user_id]\n",
    "    #print(friend_ids)\n",
    "    friends_count = len(friend_ids)\n",
    "    #print(friends_count)\n",
    "    return friends_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_friends(users[1], friendships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_connections = sum(number_of_friends(user, friendships) for user in users)\n",
    "total_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users = len(users)\n",
    "num_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_connections = total_connections / num_users\n",
    "avg_connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who are the most connected people?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2),\n",
       " (1, 3),\n",
       " (2, 3),\n",
       " (3, 3),\n",
       " (4, 2),\n",
       " (5, 3),\n",
       " (6, 2),\n",
       " (7, 2),\n",
       " (8, 3),\n",
       " (9, 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list (user_id, number_of_friends)\n",
    "num_friends_by_id = [(user[\"id\"], number_of_friends(user, friendships)) for user in users]\n",
    "num_friends_by_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 3),\n",
       " (2, 3),\n",
       " (3, 3),\n",
       " (5, 3),\n",
       " (8, 3),\n",
       " (0, 2),\n",
       " (4, 2),\n",
       " (6, 2),\n",
       " (7, 2),\n",
       " (9, 1)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the network metric degree centrality\n",
    "num_friends_by_id.sort(                                # Sort the list\n",
    "       key=lambda id_and_friends: id_and_friends[1],   # by num_friends\n",
    "       reverse=True)                                   # largest to smallest\n",
    "\n",
    "# Each pair is (user_id, num_friends):\n",
    "# [(1, 3), (2, 3), (3, 3), (5, 3), (8, 3),\n",
    "#  (0, 2), (4, 2), (6, 2), (7, 2), (9, 1)]\n",
    "num_friends_by_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/fig01-02.png\" alt=\"Analytics, Data Science, Machine Learning\" style=\"width: 800px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Betweenness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "class User(NamedTuple):\n",
    "    id: int\n",
    "    name: str\n",
    "\n",
    "users = [User(0, \"Hero\"), User(1, \"Dunn\"), User(2, \"Sue\"), User(3, \"Chi\"),\n",
    "         User(4, \"Thor\"), User(5, \"Clive\"), User(6, \"Hicks\"),\n",
    "         User(7, \"Devin\"), User(8, \"Kate\"), User(9, \"Klein\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "friend_pairs = [(0, 1), (0, 2), (1, 2), (1, 3), (2, 3), (3, 4),\n",
    "                (4, 5), (5, 6), (5, 7), (6, 8), (7, 8), (8, 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "# type alias for keeping track of Friendships\n",
    "Friendships = Dict[int, List[int]]\n",
    "\n",
    "friendships: Friendships = {user.id: [] for user in users}\n",
    "\n",
    "for i, j in friend_pairs:\n",
    "    friendships[i].append(j)\n",
    "    friendships[j].append(i)\n",
    "\n",
    "assert friendships[4] == [3, 5]\n",
    "assert friendships[8] == [6, 7, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "Path = List[int]\n",
    "\n",
    "def shortest_paths_from(from_user_id: int,\n",
    "                        friendships: Friendships) -> Dict[int, List[Path]]:\n",
    "    # A dictionary from user_id to *all* shortest paths to that user.\n",
    "    shortest_paths_to: Dict[int, List[Path]] = {from_user_id: [[]]}\n",
    "\n",
    "    # A queue of (previous user, next user) that we need to check.\n",
    "    # Starts out with all pairs (from_user, friend_of_from_user).\n",
    "    frontier = deque((from_user_id, friend_id)\n",
    "                     for friend_id in friendships[from_user_id])\n",
    "\n",
    "    # Keep going until we empty the queue.\n",
    "    while frontier:\n",
    "        # Remove the pair that's next in the queue.\n",
    "        prev_user_id, user_id = frontier.popleft()\n",
    "\n",
    "        # Because of the way we're adding to the queue,\n",
    "        # necessarily we already know some shortest paths to prev_user.\n",
    "        paths_to_prev_user = shortest_paths_to[prev_user_id]\n",
    "        new_paths_to_user = [path + [user_id] for path in paths_to_prev_user]\n",
    "        \n",
    "        # It's possible we already know a shortest path to user_id.\n",
    "        old_paths_to_user = shortest_paths_to.get(user_id, [])\n",
    "\n",
    "        # What's the shortest path to here that we've seen so far?\n",
    "        if old_paths_to_user:\n",
    "            min_path_length = len(old_paths_to_user[0])\n",
    "        else:\n",
    "            min_path_length = float('inf')\n",
    "\n",
    "        # Only keep paths that aren't too long and are actually new.\n",
    "        new_paths_to_user = [path\n",
    "                             for path in new_paths_to_user\n",
    "                             if len(path) <= min_path_length\n",
    "                             and path not in old_paths_to_user]\n",
    "\n",
    "        shortest_paths_to[user_id] = old_paths_to_user + new_paths_to_user\n",
    "\n",
    "        # Add never-seen neighbors to the frontier.\n",
    "        frontier.extend((user_id, friend_id)\n",
    "                        for friend_id in friendships[user_id]\n",
    "                        if friend_id not in shortest_paths_to)\n",
    "\n",
    "    return shortest_paths_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each from_user, for each to_user, a list of shortest paths.\n",
    "shortest_paths = {user.id: shortest_paths_from(user.id, friendships)\n",
    "                  for user in users} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: [[]],\n",
       "  1: [[1]],\n",
       "  2: [[2]],\n",
       "  3: [[1, 3], [2, 3]],\n",
       "  4: [[1, 3, 4], [2, 3, 4]],\n",
       "  5: [[1, 3, 4, 5], [2, 3, 4, 5]],\n",
       "  6: [[1, 3, 4, 5, 6], [2, 3, 4, 5, 6]],\n",
       "  7: [[1, 3, 4, 5, 7], [2, 3, 4, 5, 7]],\n",
       "  8: [[1, 3, 4, 5, 6, 8],\n",
       "   [2, 3, 4, 5, 6, 8],\n",
       "   [1, 3, 4, 5, 7, 8],\n",
       "   [2, 3, 4, 5, 7, 8]],\n",
       "  9: [[1, 3, 4, 5, 6, 8, 9],\n",
       "   [2, 3, 4, 5, 6, 8, 9],\n",
       "   [1, 3, 4, 5, 7, 8, 9],\n",
       "   [2, 3, 4, 5, 7, 8, 9]]},\n",
       " 1: {1: [[]],\n",
       "  0: [[0]],\n",
       "  2: [[2]],\n",
       "  3: [[3]],\n",
       "  4: [[3, 4]],\n",
       "  5: [[3, 4, 5]],\n",
       "  6: [[3, 4, 5, 6]],\n",
       "  7: [[3, 4, 5, 7]],\n",
       "  8: [[3, 4, 5, 6, 8], [3, 4, 5, 7, 8]],\n",
       "  9: [[3, 4, 5, 6, 8, 9], [3, 4, 5, 7, 8, 9]]},\n",
       " 2: {2: [[]],\n",
       "  0: [[0]],\n",
       "  1: [[1]],\n",
       "  3: [[3]],\n",
       "  4: [[3, 4]],\n",
       "  5: [[3, 4, 5]],\n",
       "  6: [[3, 4, 5, 6]],\n",
       "  7: [[3, 4, 5, 7]],\n",
       "  8: [[3, 4, 5, 6, 8], [3, 4, 5, 7, 8]],\n",
       "  9: [[3, 4, 5, 6, 8, 9], [3, 4, 5, 7, 8, 9]]},\n",
       " 3: {3: [[]],\n",
       "  1: [[1]],\n",
       "  2: [[2]],\n",
       "  4: [[4]],\n",
       "  0: [[1, 0], [2, 0]],\n",
       "  5: [[4, 5]],\n",
       "  6: [[4, 5, 6]],\n",
       "  7: [[4, 5, 7]],\n",
       "  8: [[4, 5, 6, 8], [4, 5, 7, 8]],\n",
       "  9: [[4, 5, 6, 8, 9], [4, 5, 7, 8, 9]]},\n",
       " 4: {4: [[]],\n",
       "  3: [[3]],\n",
       "  5: [[5]],\n",
       "  1: [[3, 1]],\n",
       "  2: [[3, 2]],\n",
       "  6: [[5, 6]],\n",
       "  7: [[5, 7]],\n",
       "  0: [[3, 1, 0], [3, 2, 0]],\n",
       "  8: [[5, 6, 8], [5, 7, 8]],\n",
       "  9: [[5, 6, 8, 9], [5, 7, 8, 9]]},\n",
       " 5: {5: [[]],\n",
       "  4: [[4]],\n",
       "  6: [[6]],\n",
       "  7: [[7]],\n",
       "  3: [[4, 3]],\n",
       "  8: [[6, 8], [7, 8]],\n",
       "  1: [[4, 3, 1]],\n",
       "  2: [[4, 3, 2]],\n",
       "  9: [[6, 8, 9], [7, 8, 9]],\n",
       "  0: [[4, 3, 1, 0], [4, 3, 2, 0]]},\n",
       " 6: {6: [[]],\n",
       "  5: [[5]],\n",
       "  8: [[8]],\n",
       "  4: [[5, 4]],\n",
       "  7: [[5, 7], [8, 7]],\n",
       "  9: [[8, 9]],\n",
       "  3: [[5, 4, 3]],\n",
       "  1: [[5, 4, 3, 1]],\n",
       "  2: [[5, 4, 3, 2]],\n",
       "  0: [[5, 4, 3, 1, 0], [5, 4, 3, 2, 0]]},\n",
       " 7: {7: [[]],\n",
       "  5: [[5]],\n",
       "  8: [[8]],\n",
       "  4: [[5, 4]],\n",
       "  6: [[5, 6], [8, 6]],\n",
       "  9: [[8, 9]],\n",
       "  3: [[5, 4, 3]],\n",
       "  1: [[5, 4, 3, 1]],\n",
       "  2: [[5, 4, 3, 2]],\n",
       "  0: [[5, 4, 3, 1, 0], [5, 4, 3, 2, 0]]},\n",
       " 8: {8: [[]],\n",
       "  6: [[6]],\n",
       "  7: [[7]],\n",
       "  9: [[9]],\n",
       "  5: [[6, 5], [7, 5]],\n",
       "  4: [[6, 5, 4], [7, 5, 4]],\n",
       "  3: [[6, 5, 4, 3], [7, 5, 4, 3]],\n",
       "  1: [[6, 5, 4, 3, 1], [7, 5, 4, 3, 1]],\n",
       "  2: [[6, 5, 4, 3, 2], [7, 5, 4, 3, 2]],\n",
       "  0: [[6, 5, 4, 3, 1, 0],\n",
       "   [7, 5, 4, 3, 1, 0],\n",
       "   [6, 5, 4, 3, 2, 0],\n",
       "   [7, 5, 4, 3, 2, 0]]},\n",
       " 9: {9: [[]],\n",
       "  8: [[8]],\n",
       "  6: [[8, 6]],\n",
       "  7: [[8, 7]],\n",
       "  5: [[8, 6, 5], [8, 7, 5]],\n",
       "  4: [[8, 6, 5, 4], [8, 7, 5, 4]],\n",
       "  3: [[8, 6, 5, 4, 3], [8, 7, 5, 4, 3]],\n",
       "  1: [[8, 6, 5, 4, 3, 1], [8, 7, 5, 4, 3, 1]],\n",
       "  2: [[8, 6, 5, 4, 3, 2], [8, 7, 5, 4, 3, 2]],\n",
       "  0: [[8, 6, 5, 4, 3, 1, 0],\n",
       "   [8, 7, 5, 4, 3, 1, 0],\n",
       "   [8, 6, 5, 4, 3, 2, 0],\n",
       "   [8, 7, 5, 4, 3, 2, 0]]}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortest_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can compute betweenness centrality\n",
    "\n",
    "betweenness_centrality = {user.id: 0.0 for user in users}\n",
    "\n",
    "for source in users:\n",
    "    for target_id, paths in shortest_paths[source.id].items():\n",
    "        if source.id < target_id:      # don't double count\n",
    "            num_paths = len(paths)     # how many shortest paths?\n",
    "            contrib = 1 / num_paths    # contribution to centrality\n",
    "            for path in paths:\n",
    "                for between_id in path:\n",
    "                    if between_id not in [source.id, target_id]:\n",
    "                        betweenness_centrality[between_id] += contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.0,\n",
       " 1: 3.5,\n",
       " 2: 3.5,\n",
       " 3: 18.0,\n",
       " 4: 20.0,\n",
       " 5: 20.5,\n",
       " 6: 6.0,\n",
       " 7: 6.0,\n",
       " 8: 8.5,\n",
       " 9: 0.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betweenness_centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users 0 and 9 have centrality 0 (as neither is on any shortest path between other users), whereas 3, 4, and 5 all have high centralities (as all three lie on many shortest paths). \n",
    "\n",
    "<img src=\"images/fig01-03.png\" alt=\"Analytics, Data Science, Machine Learning\" style=\"width: 800px;\"/>\n",
    "\n",
    "Generally the centrality numbers aren’t that meaningful themselves. What we care about is how the numbers for each node compare to the numbers for other nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Closeness Centrality\n",
    "First, for each user we compute her `farness`, which is the sum of the lengths of her shortest paths to each other user. Since we’ve already computed the shortest paths between each pair of nodes, it’s easy to add their lengths. (If there are multiple shortest paths, they all have the same length, so we can just look at the first one.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def farness(user_id: int) -> float:\n",
    "    \"\"\"the sum of the lengths of the shortest paths to each other user\"\"\"\n",
    "    return sum(len(paths[0])\n",
    "               for paths in shortest_paths[user_id].values()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after which it’s very little work to compute closeness centrality\n",
    "closeness_centrality = {user.id: 1 / farness(user.id) for user in users}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.029411764705882353,\n",
       " 1: 0.037037037037037035,\n",
       " 2: 0.037037037037037035,\n",
       " 3: 0.045454545454545456,\n",
       " 4: 0.05,\n",
       " 5: 0.05,\n",
       " 6: 0.041666666666666664,\n",
       " 7: 0.041666666666666664,\n",
       " 8: 0.03571428571428571,\n",
       " 9: 0.027777777777777776}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closeness_centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/fig01-04.png\" alt=\"Analytics, Data Science, Machine Learning\" style=\"width: 800px;\"/>\n",
    "\n",
    "There is much less variation here - even the very central nodes are still pretty far from the nodes out on the periphery.\n",
    "\n",
    "Computing `shortest paths` is kind of a pain. For this reason, `betweenness and closeness centrality` aren’t often used on large networks. The less intuitive (but generally easier to compute) `eigenvector centrality` is more frequently used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Eigenvector Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scratch.linear_algebra import Matrix, make_matrix, shape\n",
    "\n",
    "def matrix_times_matrix(m1: Matrix, m2: Matrix) -> Matrix:\n",
    "    nr1, nc1 = shape(m1)\n",
    "    nr2, nc2 = shape(m2)\n",
    "    assert nc1 == nr2, \"must have (# of columns in m1) == (# of rows in m2)\"\n",
    "\n",
    "    def entry_fn(i: int, j: int) -> float:\n",
    "        \"\"\"dot product of i-th row of m1 with j-th column of m2\"\"\"\n",
    "        return sum(m1[i][k] * m2[k][j] for k in range(nc1))\n",
    "    return make_matrix(nr1, nc2, entry_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scratch.linear_algebra import Vector, dot\n",
    "\n",
    "def matrix_times_vector(m: Matrix, v: Vector) -> Vector:\n",
    "    nr, nc = shape(m)\n",
    "    n = len(v)\n",
    "    assert nc == n, \"must have (# of cols in m) == (# of elements in v)\"\n",
    "\n",
    "    return [dot(row, v) for row in m]  # output has length nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import random\n",
    "from scratch.linear_algebra import magnitude, distance\n",
    "\n",
    "def find_eigenvector(m: Matrix,\n",
    "                     tolerance: float = 0.00001) -> Tuple[Vector, float]:\n",
    "    guess = [random.random() for _ in m]\n",
    "\n",
    "    while True:\n",
    "        result = matrix_times_vector(m, guess)    # transform guess\n",
    "        norm = magnitude(result)                  # compute norm\n",
    "        next_guess = [x / norm for x in result]   # rescale\n",
    "\n",
    "        if distance(guess, next_guess) < tolerance:\n",
    "            # convergence so return (eigenvector, eigenvalue)\n",
    "            return next_guess, norm \n",
    "        guess = next_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entry_fn(i: int, j: int):\n",
    "    return 1 if (i, j) in friend_pairs or (j, i) in friend_pairs else 0\n",
    "\n",
    "n = len(users)\n",
    "adjacency_matrix = make_matrix(n, n, entry_fn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvector_centralities, _ = find_eigenvector(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3857806077033853,\n",
       " 0.5147894100194471,\n",
       " 0.5147894100194471,\n",
       " 0.4733139122016508,\n",
       " 0.2336078915138231,\n",
       " 0.15015018804392907,\n",
       " 0.08355253092634635,\n",
       " 0.08355253092634635,\n",
       " 0.07284431114848253,\n",
       " 0.02729321230231473]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvector_centralities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/fig01-05.png\" alt=\"Analytics, Data Science, Machine Learning\" style=\"width: 800px;\"/>\n",
    "\n",
    "Users with high `eigenvector centrality` should be those who have a lot of connections, and connections to people who themselves have high centrality.\n",
    "\n",
    "Here users 1 and 2 are the most central, as they both have three connections to people who are themselves highly central. As we move away from them, people’s centralities steadily drop off.\n",
    "\n",
    "On a network this small, eigenvector centrality behaves somewhat erratically. If you try adding or subtracting links, you’ll find that small changes in the network can dramatically change the centrality numbers. In a much larger network, this would not particularly be the case.\n",
    "\n",
    "In other words, `eigenvector centralities are numbers, one per user, such that each user’s value is a constant multiple of the sum of his neighbors’ values`. In this case centrality means being connected to people who themselves are central. The more centrality you are directly connected to, the more central you are. This is of course a circular definition — `eigenvectors` are the way of breaking out of the circularity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directed Graphs\n",
    "\n",
    "### Number of endorsements\n",
    "\n",
    "We’ll `track endorsements` (source, target) that no longer represent a reciprocal relationship, but rather that source endorses target.\n",
    "\n",
    "<img src=\"images/fig01-06.png\" alt=\"Analytics, Data Science, Machine Learning\" style=\"width: 800px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "endorsements = [(0, 1), (1, 0), (0, 2), (2, 0), (1, 2),\n",
    "                (2, 1), (1, 3), (2, 3), (3, 4), (5, 4),\n",
    "                (5, 6), (7, 5), (6, 8), (8, 7), (8, 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 2, 0: 2, 2: 2, 3: 2, 4: 2, 6: 1, 5: 1, 8: 1, 7: 1, 9: 1})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "endorsement_counts = Counter(target for source, target in endorsements)\n",
    "endorsement_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`“Number of endorsements” is an easy metric to game`. All you need to do is create phony accounts and have them endorse you. Or arrange with your friends to endorse each other. (As users 0, 1, and 2 seem to have done.)\n",
    "\n",
    "`A better metric would take into account who endorses you`. Endorsements from people who have a lot of endorsements should somehow count more than endorsements from people with few endorsements. This is the essence of the **PageRank** algorithm, used by Google to rank websites based on which other websites link to them, which other websites link to those, and so on.\n",
    "\n",
    "A simplified version of **PageRank** looks like this:\n",
    "\n",
    "1. There is a total of 1.0 (or 100%) PageRank in the network.\n",
    "2. Initially this PageRank is equally distributed among nodes.\n",
    "3. At each step, a large fraction of each node’s PageRank is distributed evenly among its outgoing links.\n",
    "4. At each step, the remainder of each node’s PageRank is distributed evenly among all nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def page_rank(users: List[User],\n",
    "              endorsements: List[Tuple[int, int]],\n",
    "              damping: float = 0.85,\n",
    "              num_iters: int = 100) -> Dict[int, float]:\n",
    "    # Compute how many people each person endorses\n",
    "    outgoing_counts = Counter(target for source, target in endorsements)\n",
    "\n",
    "    # Initially distribute PageRank evenly\n",
    "    num_users = len(users)\n",
    "    pr = {user.id : 1 / num_users for user in users}\n",
    "\n",
    "    # Small fraction of PageRank that each node gets each iteration\n",
    "    base_pr = (1 - damping) / num_users\n",
    "\n",
    "    for iter in tqdm.trange(num_iters):\n",
    "        next_pr = {user.id : base_pr for user in users}  # start with base_pr\n",
    "\n",
    "        for source, target in endorsements:\n",
    "            # Add damped fraction of source pr to target\n",
    "            next_pr[target] += damping * pr[source] / outgoing_counts[source]\n",
    "\n",
    "        pr = next_pr\n",
    "\n",
    "    return pr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 112237.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Compute page rank\n",
    "pr = page_rank(users, endorsements)\n",
    "\n",
    "# Thor (user_id 4) has higher page rank than anyone else\n",
    "assert pr[4] > max(page_rank\n",
    "                   for user_id, page_rank in pr.items()\n",
    "                   if user_id != 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.1,\n",
       " 1: 0.1,\n",
       " 2: 0.1,\n",
       " 3: 0.1,\n",
       " 4: 0.14250000000000002,\n",
       " 5: 0.1,\n",
       " 6: 0.1,\n",
       " 7: 0.1,\n",
       " 8: 0.1,\n",
       " 9: 0.1}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/fig01-07.png\" alt=\"Analytics, Data Science, Machine Learning\" style=\"width: 800px;\"/>\n",
    "\n",
    "PageRank identifies user 4 (Thor) as the highest-ranked data scientist. Even though Thor has fewer endorsements (two) than users 0, 1, and 2, his endorsements carry with them rank from their endorsements. Additionally, both of his endorsers endorsed only him, which means that he doesn’t have to divide their rank with anyone else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [NetworkX](https://networkx.github.io/) - NetworkX is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks.\n",
    "- [Gephi](https://gephi.org/) - Gephi is the leading visualization and exploration software for all kinds of graphs and networks. Gephi is open-source and free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
